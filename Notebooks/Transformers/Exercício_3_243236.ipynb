{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMI0JT_YuYF3"
      },
      "source": [
        "## Exercício: Modelo de Linguagem com auto-atenção\n",
        "\n",
        "Este exercício é similar ao da aula passada, mas iremos agora treinar uma rede neural *com auto-atenção* para prever a próxima palavra de um texto, data as palavras anteriores como entrada.\n",
        "\n",
        "Na camada de auto-atenção, deve-se implementar (vide slide 34):\n",
        "- Embeddings de posição\n",
        "- Projeções lineares (WQ, WK, WV, WO)\n",
        "- Camada de feed forward (2-layer MLP)\n",
        "\n",
        "Instrucões:\n",
        "- É necessário fazer duas implementações da camada de auto-atenção: uma usando laços (ineficiente, mas fácil de entender) e outra matricial (eficiente mas difícil de entender). Usar slide 36 como referência.\n",
        "\n",
        "- Fazer um assert para garantir que o resultado das duas implementações é exatamente igual.\n",
        "\n",
        "- No treinamento, usar apenas a implementação matricial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0aNAN2662gK_"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import sklearn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhT-nVLT2gLA"
      },
      "source": [
        "## Parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUe-CsBW2gLB"
      },
      "outputs": [],
      "source": [
        "context_size = 8\n",
        "embedding_dim = 64\n",
        "hidden = 500\n",
        "batch_size = 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYbkEzdD37sZ"
      },
      "source": [
        "## Faz download e carrega o dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_UzC9pV091C",
        "outputId": "1553b04f-24c4-4027-8cab-0907f92f04df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4799, 4740)"
            ]
          },
          "execution_count": 318,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text1 = open(\"pg67724.txt\",\"r\").read()\n",
        "text1_pt = text1.split(\"\\n\\n\")[35:2675]\n",
        "\n",
        "text2 = open(\"pg67725.txt\",\"r\").read()\n",
        "text2_pt = text2.split(\"\\n\\n\")[32:2191]\n",
        "\n",
        "paragraphs = text1_pt + text2_pt\n",
        "\n",
        "cleaned_paragraphs = [paragraph.replace(\"\\n\", \" \") for paragraph in paragraphs if paragraph.strip()]\n",
        "\n",
        "len(paragraphs), len(cleaned_paragraphs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFVN2ihb33Rf"
      },
      "source": [
        "## Análise do dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSRHqe3H4ZFw",
        "outputId": "4a985c7a-ce1d-4b72-d253-c9fbbc5f9440"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11837"
            ]
          },
          "execution_count": 319,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Conta as palavras no dataset\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "def count_words(texts):\n",
        "    word_counts = Counter()\n",
        "    for text in texts:\n",
        "        word_counts.update(re.findall(r'\\w+', text.lower()))\n",
        "    return word_counts\n",
        "\n",
        "word_counts = count_words(cleaned_paragraphs)\n",
        "\n",
        "len(word_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyGVDL9KzJ_I"
      },
      "source": [
        "## Criando um vocabulário"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiP7OCo9zJ_I"
      },
      "outputs": [],
      "source": [
        "vocab_size = 3000\n",
        "\n",
        "UNK = '<UNK>'\n",
        "most_frequent_words = [UNK] + [word for word, count in word_counts.most_common(vocab_size)]\n",
        "vocab = {word: i for i, word in enumerate(most_frequent_words)}\n",
        "vocab_size = len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhbhAsZbzJ_J"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "# Function to encode a sentence into a list of indices based on a vocabulary\n",
        "def encode_sentence(sentence, vocab):\n",
        "    # Tokenize the sentence into words and punctuation marks\n",
        "    tokens = re.findall(r'\\w+|[.,!?-]', sentence.lower())\n",
        "    # Encode each token using the vocabulary, replacing unknown words with 0\n",
        "    encoded_sentence = [vocab.get(word, 0) for word in tokens]\n",
        "    return encoded_sentence\n",
        "\n",
        "# Function to decode a list of indices into a sentence using a vocabulary\n",
        "def decode_sentence(encoded_sentence, vocab):\n",
        "    words = []\n",
        "    # Iterate through each index in the encoded sentence\n",
        "    for index in encoded_sentence:\n",
        "        # Find the corresponding word in the vocabulary for the index\n",
        "        # If the index is not found in the vocabulary, replace it with \"<UNK>\"\n",
        "        word = next((word for word, code in vocab.items() if code == index), \"<UNK>\")\n",
        "        words.append(word)\n",
        "    return words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wia_ygbvzJ_J"
      },
      "source": [
        "## Classe do dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cNkjcEA2gLD"
      },
      "outputs": [],
      "source": [
        "def gera_input_target(text, context_size):\n",
        "    # Initialize lists to store contexts and targets.\n",
        "    contexts = []\n",
        "    targets = []\n",
        "\n",
        "    # Iterate over the text to generate contexts and corresponding targets.\n",
        "    for i in range(len(text) - context_size):\n",
        "        # Extract the context of size 'context_size' starting from index 'i'.\n",
        "        context = text[i: i + context_size]\n",
        "        # Retrieve the target element immediately following the context.\n",
        "        target = text[i + context_size]\n",
        "        # Append the context and target to their respective lists.\n",
        "        contexts.append(context)\n",
        "        targets.append(target)\n",
        "\n",
        "    # Return the lists of contexts and targets.\n",
        "    return contexts, targets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iy-elI1magRR"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, text, vocab, context_size):\n",
        "        # Initialize the dataset with the provided text, vocabulary, and context size.\n",
        "        # Encode each sentence in the text using the provided vocabulary.\n",
        "        self.vocab = vocab\n",
        "        self.context_size = context_size\n",
        "        self.data = [encode_sentence(sentence, self.vocab) for sentence in text]\n",
        "\n",
        "        # Initialize lists to store contexts and targets.\n",
        "        contexts_list = []\n",
        "        targets_list = []\n",
        "\n",
        "        # Iterate over the encoded data to generate inputs and targets.\n",
        "        for coded in self.data:\n",
        "            # Skip sentences shorter than the context size.\n",
        "            if len(coded) < self.context_size:\n",
        "                continue\n",
        "\n",
        "            # Check if any token in the encoded sentence is unknown (UNK).\n",
        "            if any(token == self.vocab[UNK] for token in coded):\n",
        "                continue  # Skip this example if it contains unknown tokens.\n",
        "\n",
        "            # Generate inputs and targets using the current sentence's encoded representation.\n",
        "            inputs, targets = gera_input_target(coded, context_size)\n",
        "            contexts_list.extend(inputs)\n",
        "            targets_list.extend(targets)\n",
        "\n",
        "        # Convert the lists of contexts and targets into tensors.\n",
        "        self.contexts_tensor = torch.tensor(contexts_list)\n",
        "        self.targets_tensor = torch.tensor(targets_list)\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the total number of samples in the dataset.\n",
        "        return len(self.targets_tensor)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Retrieve and return the context and target tensors for the given index.\n",
        "        return self.contexts_tensor[idx], self.targets_tensor[idx]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1aetOpmDeQd"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_text, test_text = train_test_split(cleaned_paragraphs, test_size=0.2, random_state=18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aD1CVci2zJ_J"
      },
      "outputs": [],
      "source": [
        "# Gera os dataset de treino e validação\n",
        "train_dataset = MyDataset(train_text, vocab,context_size)\n",
        "test_dataset = MyDataset(test_text, vocab, context_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gC0C5qn2zJ_J"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "sample = next(iter(train_loader))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5_-Yud0zJ_K"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVVZb8M02gLE"
      },
      "outputs": [],
      "source": [
        "# Camada de atenção para implementação em Loop\n",
        "\n",
        "def attention_loop(seq, WQ, WK, WV, WO):\n",
        "    E = []\n",
        "    for q in seq:\n",
        "        q = WQ(q)  # Apply WQ to the query vector\n",
        "        scores = []\n",
        "        for k in seq:\n",
        "            k = WK(k)  # Apply WK to the key vector\n",
        "            score = torch.dot(q, k.transpose(-1,0))  # Compute dot product of q and k\n",
        "            scores.append(score)\n",
        "        scores_tensor = torch.tensor(scores)  # Convert scores to a tensor\n",
        "        probs = scores_tensor.softmax(dim=-1)  # Normalize scores using softmax\n",
        "\n",
        "        new_embedding = 0\n",
        "        for v, p in zip(seq, probs):\n",
        "            v = WV(v)  # Apply WV to the value vector\n",
        "            new_embedding += v * p  # Weighted sum of values using probabilities\n",
        "\n",
        "        new_embedding = WO(new_embedding)  # Apply WO to the final embedding\n",
        "        E.append(new_embedding)\n",
        "\n",
        "    return torch.stack(E)  # Stack all embeddings into a tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLDS4mJ62gLE"
      },
      "outputs": [],
      "source": [
        "# Camada de atenção para implementação em martrizes\n",
        "\n",
        "def attention_matrix(Q, K, V, linearWO):\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) # shape = B,L,L\n",
        "        probs = F.softmax(scores, dim=-1) # B,L,L\n",
        "        E = torch.matmul(probs, V)  # shape = B,L,D\n",
        "        return linearWO(E)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRkwj1im2gLF",
        "outputId": "8077750f-2bf5-4b50-9819-2dac0546b5c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Função loop\n",
            "tensor([[ 0.1430,  0.1908,  0.5903, -0.2245, -0.0678],\n",
            "        [ 0.1358,  0.1837,  0.5331, -0.2078, -0.0862],\n",
            "        [ 0.1371,  0.2015,  0.5825, -0.2111, -0.0718],\n",
            "        [ 0.1236,  0.2443,  0.5987, -0.1784, -0.0689],\n",
            "        [ 0.1186,  0.1965,  0.5186, -0.1874, -0.1002]],\n",
            "       grad_fn=<StackBackward0>)\n",
            "\n",
            "Função matricial\n",
            "tensor([[ 0.1430,  0.1908,  0.5903, -0.2245, -0.0678],\n",
            "        [ 0.1358,  0.1837,  0.5331, -0.2078, -0.0862],\n",
            "        [ 0.1371,  0.2015,  0.5825, -0.2111, -0.0718],\n",
            "        [ 0.1236,  0.2443,  0.5987, -0.1784, -0.0689],\n",
            "        [ 0.1186,  0.1965,  0.5186, -0.1874, -0.1002]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "\n",
            "As saídas das duas funções são iguais: True\n"
          ]
        }
      ],
      "source": [
        "# Testando as funções\n",
        "\n",
        "# Define the dimensions for testing\n",
        "test_embedding_dim = 5\n",
        "test_vocab_size = 5\n",
        "\n",
        "# Create an embedding layer\n",
        "embedding = nn.Embedding(test_vocab_size, test_embedding_dim)\n",
        "\n",
        "# Initialize linear transformations for query, key, value, and output\n",
        "WQ = nn.Linear(test_embedding_dim, test_embedding_dim)\n",
        "WK = nn.Linear(test_embedding_dim, test_embedding_dim)\n",
        "WV = nn.Linear(test_embedding_dim, test_embedding_dim)\n",
        "WO = nn.Linear(test_embedding_dim, test_vocab_size)\n",
        "\n",
        "# Generate test input\n",
        "test_input = torch.tensor([0, 1, 2, 3, 4])\n",
        "test_embedded = embedding(test_input)\n",
        "\n",
        "# Compute attention using loop-based function\n",
        "print(f\"\\nFunção loop\")\n",
        "output_loop = attention_loop(test_embedded, WQ, WK, WV, WO)\n",
        "print(output_loop)\n",
        "\n",
        "# Compute attention using matrix-based function\n",
        "print(f\"\\nFunção matricial\")\n",
        "Q = WQ(test_embedded)\n",
        "K = WK(test_embedded)\n",
        "V = WV(test_embedded)\n",
        "output_matricial = attention_matrix(Q, K, V, WO)\n",
        "print(output_matricial)\n",
        "\n",
        "# Compare the results of the two functions\n",
        "are_equal = torch.allclose(output_matricial, output_loop)\n",
        "print(\"\\nAs saídas das duas funções são iguais:\", are_equal)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmEElVz32gLF"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, context_size, embedding_dim):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        # Initialize positional encoding matrix\n",
        "        self.pe = torch.zeros(context_size, embedding_dim)\n",
        "\n",
        "        # Compute positional encodings\n",
        "        position = torch.arange(0, context_size, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, embedding_dim, 2).float() * (-np.log(10000.0) / embedding_dim))\n",
        "        self.pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        self.pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.pe = self.pe.unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Add positional encodings to input embeddings\n",
        "        if len(x.shape) == 3:\n",
        "            _, seq_len, _ = x.size() # batch size, context size, embedding dim\n",
        "        else:\n",
        "            seq_len, _ = x.size()    # context size, embedding dim\n",
        "\n",
        "        pe = self.pe[:, :seq_len, :]\n",
        "        return x + pe.to(x.device)  # Return input embeddings with positional encodings added\n",
        "\n",
        "\n",
        "class AttentionModel_Matrix(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size,      # Vocabulary size (assuming `vocab` is defined elsewhere)\n",
        "        context_size,    # Context window size\n",
        "        embedding_dim,   # Dimensionality of word embeddings\n",
        "        hidden           # Dimensionality of hidden layer in MLP\n",
        "    ):\n",
        "        super().__init__()  # Call the constructor of the parent class\n",
        "\n",
        "        # Define embedding layer and positional encoding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.pos_encoding = PositionalEncoding(context_size, embedding_dim)\n",
        "\n",
        "        # Linear transformations for Q, K, V, and output\n",
        "        self.linearWQ = nn.Linear(embedding_dim, embedding_dim)\n",
        "        self.linearWK = nn.Linear(embedding_dim, embedding_dim)\n",
        "        self.linearWV = nn.Linear(embedding_dim, embedding_dim)\n",
        "        self.linearWO = nn.Linear(embedding_dim, embedding_dim)\n",
        "\n",
        "        # Fully connected layers for classification\n",
        "        self.fc1 = nn.Linear(context_size * embedding_dim, hidden)\n",
        "        self.fc2 = nn.Linear(hidden, vocab_size)\n",
        "\n",
        "    def self_attention_layer(self, q, k, v, wo):\n",
        "        # Compute self-attention scores\n",
        "        scores = torch.matmul(q, k.transpose(-2, -1)) # shape = B,L,L\n",
        "        probs = F.softmax(scores, dim=-1)  # Apply softmax to obtain attention weights\n",
        "        e = torch.matmul(probs, v)  # Compute weighted sum of values (V)\n",
        "        return wo(e)  # Apply linear transformation to the weighted sum\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Embed input tokens and add positional encodings\n",
        "        embedding_input = self.embedding(x)\n",
        "        embedding_input = self.pos_encoding(embedding_input)\n",
        "\n",
        "        # Linear transformations for Q, K, and V\n",
        "        Q = self.linearWQ(embedding_input)\n",
        "        K = self.linearWK(embedding_input)\n",
        "        V = self.linearWV(embedding_input)\n",
        "\n",
        "        # Compute self-attention\n",
        "        E = self.self_attention_layer(Q, K, V, self.linearWO)\n",
        "\n",
        "        # Reshape for fully connected layers\n",
        "        if len(E.shape) == 3:\n",
        "            batch_size, context_size, vocab_size = E.shape\n",
        "            E = E.view(batch_size, -1)\n",
        "        else:\n",
        "            batch_size, context_size = E.shape\n",
        "            E = E.view(batch_size, -1)\n",
        "\n",
        "        # Apply fully connected layers\n",
        "        o = self.fc1(E)\n",
        "        o = F.relu(o)\n",
        "        logits = self.fc2(o)\n",
        "\n",
        "        return logits\n",
        "\n",
        "# Create an instance of the AttentionModel_Matrix class\n",
        "model_matrix = AttentionModel_Matrix(vocab_size, context_size, embedding_dim, hidden)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3W176hxT2gLF",
        "outputId": "d4d872b8-3f83-43b3-8246-06e62e5ce631"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quantidade de parâmetros treináveis: 13\n",
            "Parâmetros treináveis:\n",
            "torch.Size([3001, 64])\n",
            "torch.Size([64, 64])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 64])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 64])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 64])\n",
            "torch.Size([64])\n",
            "torch.Size([500, 512])\n",
            "torch.Size([500])\n",
            "torch.Size([3001, 500])\n",
            "torch.Size([3001])\n",
            "Número total de parâmetros: 1968705\n"
          ]
        }
      ],
      "source": [
        "# Verificando os parâmetros treináveis\n",
        "parametros_treinaveis = list(model_matrix.parameters())\n",
        "\n",
        "# Imprima a quantidade de parâmetros treináveis e a lista de parâmetros\n",
        "print(f'Quantidade de parâmetros treináveis: {len(parametros_treinaveis)}')\n",
        "print(\"Parâmetros treináveis:\")\n",
        "for parametro in parametros_treinaveis:\n",
        "    print(parametro.shape)\n",
        "\n",
        "total_parametros = 0\n",
        "\n",
        "# Itere sobre os parâmetros treináveis e calcule o número total de parâmetros\n",
        "for parametro in parametros_treinaveis:\n",
        "    if len(parametro.shape) == 2:  # Verifica se é um tensor de peso de camada totalmente conectada\n",
        "        total_parametros += (parametro.shape[0] * parametro.shape[1])  # Multiplica os tamanhos da entrada e saída\n",
        "    elif len(parametro.shape) == 1:  # Verifica se é um tensor de bias\n",
        "        total_parametros += parametro.shape[0]  # Adiciona o número de parâmetros de bias\n",
        "\n",
        "# Imprima o número total de parâmetros\n",
        "print(f'Número total de parâmetros: {total_parametros}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvkXmj1r2gLF",
        "outputId": "f5c3959c-e7ab-4508-cd3a-3382f1444d31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AttentionModel_Matrix(\n",
            "  (embedding): Embedding(3001, 64)\n",
            "  (pos_encoding): PositionalEncoding()\n",
            "  (linearWQ): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (linearWK): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (linearWV): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (linearWO): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (fc1): Linear(in_features=512, out_features=500, bias=True)\n",
            "  (fc2): Linear(in_features=500, out_features=3001, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Camadas da Rede\n",
        "print(model_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmsD59TfzJ_K"
      },
      "outputs": [],
      "source": [
        "sample = next(iter(train_loader))\n",
        "input = sample[0]\n",
        "target = sample[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYKqtW_-2gLG"
      },
      "outputs": [],
      "source": [
        "output = model_matrix(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "um0lR4mNzJ_K",
        "outputId": "e6041da8-ca7f-4c9d-b28b-9e1250e820f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([2844,  288,  419,  419, 1962, 1032,  288, 1962,  419,  218,  626, 1947,\n",
              "         662,  419])"
            ]
          },
          "execution_count": 333,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output.argmax(dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "la-b-f8jzJ_L",
        "outputId": "f040cef4-e409-4d20-d335-a3133aaeb63c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([14])"
            ]
          },
          "execution_count": 334,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UngUhyu7zJ_L"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wntaV50nzJ_L",
        "outputId": "a054092b-d801-4c60-eb75-85abfe57151d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 335,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Verifica se há uma GPU disponível e define o dispositivo para GPU se possível, caso contrário, usa a CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRwSPiwizJ_L",
        "outputId": "deeaf6a8-6b83-45bf-8213-7334de1d0c6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial Loss: 8.0027, n        Initial Perplexity: 2989.056884765625\n",
            "Epoch [1/15],             Loss Treinamento: 8.0027,             PPL Treinamento: 2989.0513,             Loss Teste: 7.8811,             PPL Teste: 2646.8284\n",
            "Epoch [2/15],             Loss Treinamento: 7.7705,             PPL Treinamento: 2369.6553,             Loss Teste: 7.8080,             PPL Teste: 2460.2358\n",
            "Epoch [3/15],             Loss Treinamento: 7.5043,             PPL Treinamento: 1815.8245,             Loss Teste: 7.6810,             PPL Teste: 2166.7964\n",
            "Epoch [4/15],             Loss Treinamento: 7.0945,             PPL Treinamento: 1205.3552,             Loss Teste: 7.3799,             PPL Teste: 1603.4224\n",
            "Epoch [5/15],             Loss Treinamento: 6.2855,             PPL Treinamento: 536.7534,             Loss Teste: 6.5350,             PPL Teste: 688.8222\n",
            "Epoch [6/15],             Loss Treinamento: 4.2119,             PPL Treinamento: 67.4825,             Loss Teste: 6.7213,             PPL Teste: 829.9271\n",
            "Epoch [7/15],             Loss Treinamento: 2.7490,             PPL Treinamento: 15.6263,             Loss Teste: 5.1733,             PPL Teste: 176.4923\n",
            "Epoch [8/15],             Loss Treinamento: 6.4863,             PPL Treinamento: 656.1016,             Loss Teste: 7.4858,             PPL Teste: 1782.4719\n",
            "Epoch [9/15],             Loss Treinamento: 6.8297,             PPL Treinamento: 924.8749,             Loss Teste: 6.3923,             PPL Teste: 597.2196\n",
            "Epoch [10/15],             Loss Treinamento: 4.4501,             PPL Treinamento: 85.6336,             Loss Teste: 6.8889,             PPL Teste: 981.3521\n",
            "Epoch [11/15],             Loss Treinamento: 3.8746,             PPL Treinamento: 48.1650,             Loss Teste: 6.1148,             PPL Teste: 452.5260\n",
            "Epoch [12/15],             Loss Treinamento: 3.6574,             PPL Treinamento: 38.7599,             Loss Teste: 6.5471,             PPL Teste: 697.2303\n",
            "Epoch [13/15],             Loss Treinamento: 2.4478,             PPL Treinamento: 11.5625,             Loss Teste: 5.7886,             PPL Teste: 326.5641\n",
            "Epoch [14/15],             Loss Treinamento: 2.6613,             PPL Treinamento: 14.3144,             Loss Teste: 4.9087,             PPL Teste: 135.4631\n",
            "Epoch [15/15],             Loss Treinamento: 2.5831,             PPL Treinamento: 13.2381,             Loss Teste: 4.9436,             PPL Teste: 140.2674\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model_matrix.parameters(), lr=0.1)\n",
        "model_matrix.to(device)\n",
        "\n",
        "# Calculate loss before training\n",
        "model_matrix.eval()  # Set the model to evaluation mode\n",
        "initial_loss = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in train_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        logits = model_matrix(inputs)\n",
        "        initial_loss += criterion(logits, targets)\n",
        "\n",
        "    avg_loss = initial_loss / len(train_loader)\n",
        "\n",
        "initial_PPL = torch.exp(avg_loss)\n",
        "print(f'Initial Loss: {avg_loss:.4f}, n\\\n",
        "        Initial Perplexity: {initial_PPL}')\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 15\n",
        "for epoch in range(num_epochs):\n",
        "    model_matrix.train()\n",
        "    running_loss = 0\n",
        "    for inputs, targets in train_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        logits = model_matrix(inputs)\n",
        "        loss_train = criterion(logits, targets)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss_train.item()\n",
        "\n",
        "        ppl_train = torch.exp(loss_train)\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "\n",
        "    model_matrix.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            logits = model_matrix(inputs)\n",
        "\n",
        "    loss_test = criterion(logits, targets)\n",
        "    ppl_test = torch.exp(loss_test)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], \\\n",
        "            Loss Treinamento: {loss_train.item():.4f}, \\\n",
        "            PPL Treinamento: {ppl_train.item():.4f}, \\\n",
        "            Loss Teste: {loss_test.item():.4f}, \\\n",
        "            PPL Teste: {ppl_test.item():.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1zhxVqfzJ_M"
      },
      "source": [
        "## Exemplo de uso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PExkoWOzJ_M",
        "outputId": "884e4923-1a50-41c0-9334-143446d55f50"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'dahi hirtos velhos perdia pequeno resignação viii outr murmurio amigo'"
            ]
          },
          "execution_count": 337,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def generate_text(model: AttentionModel_Matrix, length: int, vocab: vocab, context_size):\n",
        "\n",
        "    # Ensure that the length is at least equal to the context size\n",
        "    assert length > context_size\n",
        "\n",
        "    # Initialize the sentence with random words from the vocabulary\n",
        "    sentence = random.sample(range(0, vocab_size), context_size)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        while len(sentence) < length:\n",
        "            x = torch.unsqueeze(torch.asarray(sentence[-context_size:]), dim=0).to(device)\n",
        "            y = model(x).squeeze()\n",
        "            y = nn.Softmax(dim=0)(y)\n",
        "\n",
        "            # Choose the next word according to probabilities\n",
        "            y = random.choices(range(0, vocab_size), y)\n",
        "            sentence.append(y[0])\n",
        "\n",
        "    return ' '.join(decode_sentence(sentence, vocab))\n",
        "\n",
        "\n",
        "max_length= 10\n",
        "generate_text(model_matrix, max_length, vocab, context_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AxYgh0m2gLH"
      },
      "source": [
        "## Referências\n",
        "\n",
        "César Bastos da Silva\n",
        "\n",
        "Ramon Simões Abilio"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}